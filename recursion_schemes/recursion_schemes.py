from tqdm import tqdm
import numpy as np
import time
import math
import scipy
import scipy.stats
import copy
from utils.config import *
from bayesian_agents.rsaState import RSA_State
from bayesian_agents.rsaWorld import RSA_World
from utils.image_and_text_utils import max_sentence_length,index_to_char,char_to_index,devectorize_caption,\
	sentence_likelihood,largest_indices,vectorize_caption

###
"""
Recursion schemes for the RSA
"""
###

# you should call this so that running unroll beam prints this out
# calculates likelihood of caption being generated by a speaker
def likelihood(self,depth=0,which_image=0,speaker_rationality=1.0,speaker=0,listener_rationality=1.0,img_prior=np.log(np.asarray([0.5,0.5])),start_from=""):

	self.speaker_rationality=speaker_rationality
	self.listener_rationality=listener_rationality
	self.image_priors=np.log(np.ones((max_sentence_length+1,self.images.shape[0]))*(1/self.images.shape[0]))
	self.image_priors[0]=img_prior
	sentence = np.expand_dims(np.expand_dims(vectorize_caption(start_from)[0],0),-1)
	self.context_sentence = copy.deepcopy(sentence)

	likelihood = {}

	for i in range(1,max_sentence_length):
		self.i = i
		char = np.squeeze(sentence)[i]
		s = np.squeeze(self.speaker(img_idx=which_image,depth=depth))
		likelihood[i] = s[char]
		if index_to_char[char] == stop_token:
			break

	print(start_from,np.prod([np.exp(p) for (l,p) in likelihood.items()]))

def ana_greedy(rsa,initial_world_prior,speaker_rationality,speaker, target, pass_prior=True,listener_rationality=1.0,depth=0,start_from=[]):


	"""
	speaker_rationality,listener_rationality: 
		
		see speaker and listener code for what they do: control strength of conditioning
	
	depth: 
		
		the number of levels of RSA: depth 0 uses listeral speaker to unroll, depth n uses speaker n to unroll, and listener n to update at each step
	
	start_from:

		a partial caption you start the unrolling from

	img_prior:

		a prior on the world to start with 
	"""


	# this RSA passes along a state: see rsa_state
	state = RSA_State(initial_world_prior, listener_rationality=listener_rationality)
	# state.image_priors[:]=img_prior

	context_sentence = ['^']+start_from
	state.context_sentence=context_sentence


	world=RSA_World(target=target,rationality=speaker_rationality,speaker=speaker)

	probs=[]
	for timestep in tqdm(range(len(start_from)+1,max_sentence_length)):

		state.timestep=timestep
		s = rsa.speaker(state=state,world=world,depth=depth)
		# print("S:",s)	
		# print(s)
		segment = np.argmax(s)
		# print("s",rsa.idx2seg[segment])
		prob = np.max(s)
		probs.append(prob)

		if pass_prior:

			l = rsa.listener(state=state,utterance=segment,depth=depth)
			state.world_priors[state.timestep]=l
		state.context_sentence += [rsa.idx2seg[segment]]
		if (rsa.idx2seg[segment] == stop_token[rsa.seg_type]):
			break

	summed_probs = np.sum(np.asarray(probs))

	world_posterior = state.world_priors[:state.timestep+1][:5]

	return [("".join(state.context_sentence),summed_probs)]

#But within the n-th order ethno-metapragmatic perspective, this creative indexical effect is the motivated realization, or performable execution, of an already constituted framework of semiotic value.
def ana_beam(rsa,initial_world_prior,speaker_rationality, target,speaker, pass_prior=True,listener_rationality=1.0,depth=0,start_from=[],beam_width=len(sym_set),cut_rate=1,decay_rate=0.0,beam_decay=0,):
	"""
	speaker_rationality,listener_rationality: 
		
		see speaker and listener code for what they do: control strength of conditioning
	
	depth: 
		
		the number of levels of RSA: depth 0 uses listeral speaker to unroll, depth n uses speaker n to unroll, and listener n to update at each step
	
	start_from:
		a partial caption you start the unrolling from
	img_prior:
		a prior on the world to start with 
	which_image: 
		which of the images in the prior should be targeted?
	beam width: width beam is cut down to every cut_rate iterations of the unrolling
	cut_rate: how often beam is cut down to beam_width
	beam_decay: amount by which beam_width is lessened after each iteration 
	decay_rate: a multiplier that makes later decisions in the unrolling matter less: 0.0 does no decay. negative decay makes start matter more
	"""

	state = RSA_State(initial_world_prior, listener_rationality=listener_rationality)
	# state.image_priors[:]=img_prior

	context_sentence = start_from
	state.context_sentence=context_sentence


	world=RSA_World(target=target,rationality=speaker_rationality,speaker=speaker)



	context_sentence = start_from
	state.context_sentence=context_sentence


	sent_worldprior_prob = [(state.context_sentence,state.world_priors,0.0)]

	final_sentences=[]

	toc = time.time()
	for timestep in tqdm(range(len(start_from)+1,max_sentence_length)):
		
		
		state.timestep=timestep

		new_sent_worldprior_prob = []
		for sent,worldpriors,old_prob in sent_worldprior_prob:

			state.world_priors=worldpriors

			if state.timestep > 1:

				state.context_sentence = sent[:-1]
				seg = sent[-1]

				if depth>0 and pass_prior:

					l=rsa.listener(state=state,utterance=rsa.seg2idx[seg],depth=depth)
					state.world_priors[state.timestep-1]=copy.deepcopy(l)		

			state.context_sentence = sent

			# out = rsa.speaker(state=state,img_idx=which_image,depth=depth)
			s = rsa.speaker(state=state,world=world,depth=depth)	
			
			for seg,prob in enumerate(np.squeeze(s)):

				new_sentence = copy.deepcopy(sent)

				# conditional to deal with captions longer than max sentence length
				# if state.timestep<max_sentence_length+1:
				new_sentence += [rsa.idx2seg[seg]]
				# else: new_sentence = np.expand_dims(np.expand_dims(np.concat([np.squeeze(new_sentence)[:-1],[seg]],axis=0),0),-1)
				
				state.context_sentence = new_sentence

				new_prob = (prob*(1/math.pow(state.timestep,decay_rate)))+old_prob


				# print("beam listener",rsa.word2ord[seg], l)

				new_sent_worldprior_prob.append((new_sentence,worldpriors,new_prob))

		rsa.flush_cache()
		sent_worldprior_prob = sorted(new_sent_worldprior_prob,key=lambda x:x[-1],reverse=True)

		if state.timestep%cut_rate == 0:
			# cut down to size
			sent_worldprior_prob = sent_worldprior_prob[:beam_width]
			new_sent_worldprior_prob = []
			
			for sent,worldprior,prob in sent_worldprior_prob:
				# print("".join(sent),np.exp(prob))
				# print(state.timestep)
				if sent[-1] == stop_token[rsa.seg_type]:
					final_sentence = copy.deepcopy(sent)
					final_sentences.append((final_sentence,prob))
					# print("REMOVED SENTENCE")
				else: 
					new_triple = copy.deepcopy((sent,worldprior,prob))
					new_sent_worldprior_prob.append(new_triple)

			sent_worldprior_prob = new_sent_worldprior_prob



			if len(final_sentences)>=50:
			# 	# print("beam unroll time",tic-toc)
			# 	# print(state.image_priors[:])
				sentences = sorted(final_sentences,key=lambda x : x[-1],reverse=True)
				output = []
				for i,(sent,prob) in enumerate(sentences):

					output.append(("".join(sent),prob))

				return output
			# 		# print(sentences)
			# 		for i,(sent,prob) in enumerate(sentences):

			# 			output.append(("".join([rsa.idx2word[idx] for idx in np.squeeze(sent)]),prob))

			# 		return output
			# 	return "COMPLETE"
			# 	return "".join([rsa.idx2word[idx] for idx in np.squeeze(final_sentences[0])])

		if beam_decay < beam_width:
			beam_width-=beam_decay
		# print("decayed beam width by "+str(beam_decay)+"; beam_width now: "+str(beam_width))

	else: 
		sentences = sorted(final_sentences,key=lambda x : x[-1],reverse=True)

		output = []
		# print(sentences)
		for i,(sent,prob) in enumerate(sentences):

			output.append(("".join(sent),prob))

		return output

